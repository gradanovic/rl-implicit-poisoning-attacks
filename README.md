# Implicit Poisoning Attacks in Two-Agent Reinforcement Learning

This respository contains the code for running the experiments in the paper *Implicit Poisoning Attacks in Two-Agent Reinforcement Learning: Adversarial Policies for Training-Time Attacks*. The code is located in two folders: *experiments_for_alternating_policy_updates* (Section 5.2 of the paper) and *experiments_for_conservative_policy_search* (Section 5.1 of the paper). These two folders have their own README files with instructions on how to run the corresponding code.
